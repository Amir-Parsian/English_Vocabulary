{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding high-frequency words tweets\n",
    "In this notebook, a map-reduce procedure is used here to find words which have a high frequency in the unique tweets (this means retweets are excluded from analysis).\n",
    "\n",
    "Download a tweets from  json from archive.org (https://archive.org/search.php?query=tweets). For every given minute there is .bz2 file and all files for every hour is given in separate folders. These files contains tweets in form of json.\n",
    "\n",
    "Mapper and reducer files are below. The analysis is for one hour of tweets.\n",
    "The first line in the cell save the rest of the cell as .py file. If you want to do this manually, remove the first line and save the cell content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper_vocab_freq.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper_vocab_freq.py \n",
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import json\n",
    "\n",
    "      \n",
    "for currentTweet in sys.stdin:\n",
    "    try:\n",
    "        if currentTweet.strip() != \"\":  \n",
    "                currentTweet = currentTweet.lower().strip()\n",
    "            \n",
    "        json_dic = json.loads(currentTweet)\n",
    "        if 'text' in json_dic:\n",
    "            currentTweetText = json_dic['text']\n",
    "            # The following line replace all special character in the string with a space\n",
    "            currentTweetText = currentTweetText.translate ({ord(ch): \" \" for ch in \"!@#$%^&*()[]{};:,./<>?\\|`~-=_+0123456789\"})\n",
    "            list_of_words = currentTweetText.lower().split()\n",
    "            for word in list_of_words:\n",
    "                print(word,1)\n",
    "    except:\n",
    "        print('Error',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py \n",
    "#!/usr/bin/env python\n",
    "# source for reducer file: https://www.michael-noll.com/tutorials/writing-an-hadoop-mapreduce-program-in-python/\n",
    "import sys\n",
    "\n",
    "current_word = None\n",
    "current_count = 0\n",
    "word = None\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    word, count = line.split(' ', 1)\n",
    "    try:\n",
    "        count = int(count)\n",
    "    except ValueError:\n",
    "        print('count_error')\n",
    "    if current_word == word:\n",
    "        current_count += count\n",
    "    else:\n",
    "        if current_word:\n",
    "            print(current_word, current_count)\n",
    "        current_count = count\n",
    "        current_word = word\n",
    "\n",
    "if current_word == word:\n",
    "    print(current_word, current_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run map reduce \n",
    " run the following command in the command line:\n",
    " \n",
    " *bzcat *.bz2 | ./mapper_unique_tweets.py | sort -k1,1 | ./reducer.py*\n",
    " \n",
    " Another alternative is to write the above command in a shell script as follows. This .sh file write the result in output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapreduce.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapreduce.sh\n",
    "bzcat *.bz2 | ./mapper_vocab_freq.py | sort -k1,1 | ./reducer.py > output.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that you can run the .sh file and print the output text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 137649\n"
     ]
    }
   ],
   "source": [
    "!mapreduce.sh\n",
    "!cat output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00.json.bz2\n",
      "01.json.bz2\n",
      "02.json.bz2\n",
      "03.json.bz2\n",
      "04.json.bz2\n",
      "05.json.bz2\n",
      "06.json.bz2\n",
      "07.json.bz2\n",
      "08.json.bz2\n",
      "09.json.bz2\n",
      "10.json.bz2\n",
      "11.json.bz2\n",
      "12.json.bz2\n",
      "13.json.bz2\n",
      "14.json.bz2\n",
      "15.json.bz2\n",
      "16.json.bz2\n",
      "17.json.bz2\n",
      "18.json.bz2\n",
      "19.json.bz2\n",
      "20.json.bz2\n",
      "21.json.bz2\n",
      "22.json.bz2\n",
      "23.json.bz2\n",
      "24.json.bz2\n",
      "25.json.bz2\n",
      "26.json.bz2\n",
      "27.json.bz2\n",
      "28.json.bz2\n",
      "29.json.bz2\n",
      "30.json.bz2\n",
      "31.json.bz2\n",
      "32.json.bz2\n",
      "33.json.bz2\n",
      "34.json.bz2\n",
      "35.json.bz2\n",
      "36.json.bz2\n",
      "37.json.bz2\n",
      "38.json.bz2\n",
      "39.json.bz2\n",
      "40.json.bz2\n",
      "41.json.bz2\n",
      "42.json.bz2\n",
      "43.json.bz2\n",
      "44.json.bz2\n",
      "45.json.bz2\n",
      "46.json.bz2\n",
      "47.json.bz2\n",
      "48.json.bz2\n",
      "49.json.bz2\n",
      "50.json.bz2\n",
      "51.json.bz2\n",
      "52.json.bz2\n",
      "53.json.bz2\n",
      "54.json.bz2\n",
      "55.json.bz2\n",
      "56.json.bz2\n",
      "57.json.bz2\n",
      "58.json.bz2\n",
      "59.json.bz2\n",
      "English_Vocabulary.ipynb\n",
      "LICENSE\n",
      "Tweets_MapReduce.ipynb\n",
      "mapper_.py\n",
      "mapper_count_words.py\n",
      "mapper_tweets_.py\n",
      "mapper_unique_tweets.py\n",
      "mapper_vocab_freq.py\n",
      "mapreduce.sh\n",
      "output.txt\n",
      "reducer.py\n",
      "sum_results.py\n",
      "twitter-stream-2020-11-01\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
